{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c0a472-6cc8-434b-9bfa-ae00b8c98076",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7026052-b90c-4553-8d21-52366e15838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from scipy.sparse import lil_matrix\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f385bf-113d-47d1-951f-52a639157c3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647d482-dbc5-4e30-8322-c0b1a5b9bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentPreprocessor:\n",
    "    def __init__(self, dataset_path):\n",
    "        self.df = pd.read_csv(dataset_path)\n",
    "        self.chat_words = {\n",
    "            \"AFAIK\": \"As Far As I Know\",\n",
    "            \"AFK\": \"Away From Keyboard\",\n",
    "            \"ASAP\": \"As Soon As Possible\",\n",
    "            \"ATK\": \"At The Keyboard\",\n",
    "            \"ATM\": \"At The Moment\",\n",
    "            \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "            \"BAK\": \"Back At Keyboard\",\n",
    "            \"BBL\": \"Be Back Later\",\n",
    "            \"BBS\": \"Be Back Soon\",\n",
    "            \"BFN\": \"Bye For Now\",\n",
    "            \"B4N\": \"Bye For Now\",\n",
    "            \"BRB\": \"Be Right Back\",\n",
    "            \"BRT\": \"Be Right There\",\n",
    "            \"BTW\": \"By The Way\",\n",
    "            \"B4\": \"Before\",\n",
    "            \"CU\": \"See You\",\n",
    "            \"CUL8R\": \"See You Later\",\n",
    "            \"CYA\": \"See You\",\n",
    "            \"FAQ\": \"Frequently Asked Questions\",\n",
    "            \"FC\": \"Fingers Crossed\",\n",
    "            \"FWIW\": \"For What It's Worth\",\n",
    "            \"FYI\": \"For Your Information\",\n",
    "            \"GAL\": \"Get A Life\",\n",
    "            \"GG\": \"Good Game\",\n",
    "            \"GN\": \"Good Night\",\n",
    "            \"GMTA\": \"Great Minds Think Alike\",\n",
    "            \"GR8\": \"Great!\",\n",
    "            \"IC\": \"I See\",\n",
    "            \"ICQ\": \"I Seek you (also a chat program)\",\n",
    "            \"ILU\": \"ILU: I Love You\",\n",
    "            \"IMHO\": \"In My Honest/Humble Opinion\",\n",
    "            \"IMO\": \"In My Opinion\",\n",
    "            \"IOW\": \"In Other Words\",\n",
    "            \"IRL\": \"In Real Life\",\n",
    "            \"KISS\": \"Keep It Simple, Stupid\",\n",
    "            \"LDR\": \"Long Distance Relationship\",\n",
    "            \"LMAO\": \"Laugh My A.. Off\",\n",
    "            \"LOL\": \"Laughing Out Loud\",\n",
    "            \"LTNS\": \"Long Time No See\",\n",
    "            \"L8R\": \"Later\",\n",
    "            \"MTE\": \"My Thoughts Exactly\",\n",
    "            \"M8\": \"Mate\",\n",
    "            \"NRN\": \"No Reply Necessary\",\n",
    "            \"OIC\": \"Oh I See\",\n",
    "            \"PITA\": \"Pain In The A..\",\n",
    "            \"PRT\": \"Party\",\n",
    "            \"PRW\": \"Parents Are Watching\",\n",
    "            \"QPSA?\": \"Que Pasa?\",\n",
    "            \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "            \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "            \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
    "            \"SK8\": \"Skate\",\n",
    "            \"STATS\": \"Your sex and age\",\n",
    "            \"ASL\": \"Age, Sex, Location\",\n",
    "            \"THX\": \"Thank You\",\n",
    "            \"TTFN\": \"Ta-Ta For Now!\",\n",
    "            \"TTYL\": \"Talk To You Later\",\n",
    "            \"U\": \"You\",\n",
    "            \"U2\": \"You Too\",\n",
    "            \"U4E\": \"Yours For Ever\",\n",
    "            \"WB\": \"Welcome Back\",\n",
    "            \"WTF\": \"What The F...\",\n",
    "            \"WTG\": \"Way To Go!\",\n",
    "            \"WUF\": \"Where Are You From?\",\n",
    "            \"W8\": \"Wait...\",\n",
    "            \"7K\": \"Sick:-D Laugher\",\n",
    "            \"TFW\": \"That feeling when\",\n",
    "            \"MFW\": \"My face when\",\n",
    "            \"MRW\": \"My reaction when\",\n",
    "            \"IFYP\": \"I feel your pain\",\n",
    "            \"TNTL\": \"Trying not to laugh\",\n",
    "            \"JK\": \"Just kidding\",\n",
    "            \"IDC\": \"I don't care\",\n",
    "            \"ILY\": \"I love you\",\n",
    "            \"IMU\": \"I miss you\",\n",
    "            \"ADIH\": \"Another day in hell\",\n",
    "            \"ZZZ\": \"Sleeping, bored, tired\",\n",
    "            \"WYWH\": \"Wish you were here\",\n",
    "            \"TIME\": \"Tears in my eyes\",\n",
    "            \"BAE\": \"Before anyone else\",\n",
    "            \"FIMH\": \"Forever in my heart\",\n",
    "            \"BSAAW\": \"Big smile and a wink\",\n",
    "            \"BWL\": \"Bursting with laughter\",\n",
    "            \"BFF\": \"Best friends forever\",\n",
    "            \"CSL\": \"Can't stop laughing\"\n",
    "        }\n",
    "\n",
    "    def preprocess(self):\n",
    "        print(\"Starting preprocessing...\")\n",
    "        self.lowercase()\n",
    "        print(\"Converted text to lowercase.\")\n",
    "        self.remove_html_tags()\n",
    "        print(\"Removed HTML tags.\")\n",
    "        self.remove_url()\n",
    "        print(\"Removed URLs.\")\n",
    "        self.remove_punctuation()\n",
    "        print(\"Removed punctuation.\")\n",
    "        self.chat_conversion()\n",
    "        print(\"Converted chat words.\")\n",
    "        self.remove_stopwords()\n",
    "        print(\"Removed stopwords.\")\n",
    "        self.remove_emoji()\n",
    "        print(\"Removed emojis.\")\n",
    "        self.tokenize()\n",
    "        print(\"Tokenized text.\")\n",
    "        print(\"Preprocessing complete.\")\n",
    "        return self.df['review']\n",
    "\n",
    "    def lowercase(self):\n",
    "        self.df['review'] = self.df['review'].str.lower()\n",
    "\n",
    "    def remove_html_tags(self):\n",
    "        pattern = re.compile('<.*?>')\n",
    "        self.df['review'] = self.df['review'].apply(lambda x: pattern.sub(r'', x))\n",
    "\n",
    "    def remove_url(self):\n",
    "        pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        self.df['review'] = self.df['review'].apply(lambda x: pattern.sub(r'', x))\n",
    "\n",
    "    def remove_punctuation(self):\n",
    "        punc = string.punctuation\n",
    "        self.df['review'] = self.df['review'].apply(lambda x: x.translate(str.maketrans('', '', punc)))\n",
    "\n",
    "    def chat_conversion(self):\n",
    "        self.df['review'] = self.df['review'].apply(self._chat_conversion_helper)\n",
    "\n",
    "    def _chat_conversion_helper(self, text):\n",
    "        new_text = []\n",
    "        for word in text.split():\n",
    "            if word.upper() in self.chat_words:\n",
    "                new_text.append(self.chat_words[word.upper()])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        return \" \".join(new_text)\n",
    "\n",
    "    def remove_stopwords(self):\n",
    "        stopword = stopwords.words('english')\n",
    "        self.df['review'] = self.df['review'].apply(\n",
    "            lambda x: \" \".join([word for word in x.split() if word not in stopword]))\n",
    "\n",
    "    def remove_emoji(self):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        self.df['review'] = self.df['review'].apply(lambda x: emoji_pattern.sub(r'', x))\n",
    "\n",
    "    def tokenize(self):\n",
    "        self.df['review'] = self.df['review'].apply(word_tokenize)\n",
    "\n",
    "    def show_before_after(self, sample_size=10 ):\n",
    "        original_reviews = self.df['review'].head(sample_size).copy()\n",
    "        preprocessed_reviews = self.preprocess().head(sample_size)\n",
    "    \n",
    "        comparison_df = pd.DataFrame({\n",
    "            'Original Review': original_reviews,\n",
    "            'Preprocessed Review': preprocessed_reviews\n",
    "        })\n",
    "    \n",
    "        print(\"Before and After Preprocessing:\")\n",
    "        print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732793a-9328-4dbd-8928-866c4f5b1432",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Embedding with glove pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575bffde-11b8-478f-a3f3-1d87c5576a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GloveEmbeddingLoader:\n",
    "    def __init__(self, glove_file_path, dataset_path, embedding_dim=200):\n",
    "        self.glove_file_path = glove_file_path\n",
    "        self.dataset_path = dataset_path\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = None\n",
    "        self.vocabulary = None\n",
    "        self.word_to_id = None\n",
    "        self.id_to_word = None\n",
    "        self.embedding_matrix = None\n",
    "\n",
    "    def load_glove_embeddings(self):\n",
    "        print(\"Loading GloVe embeddings...\")\n",
    "        self.embeddings = {}\n",
    "        with open(self.glove_file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                self.embeddings[word] = vector\n",
    "        print(\"GloVe embeddings loaded.\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Load and preprocess the dataset.\"\"\"\n",
    "        print(\"Starting data preprocessing...\")\n",
    "        preprocessor = SentimentPreprocessor(self.dataset_path)\n",
    "        preprocessor.preprocess()\n",
    "        self.corpus = preprocessor.df['review'].tolist()\n",
    "        print(\"Data preprocessing complete.\")\n",
    "\n",
    "    def build_vocabulary(self, sentences):\n",
    "        print(\"Building vocabulary...\")\n",
    "        word_counts = Counter(word for sentence in sentences for word in sentence)\n",
    "        self.vocabulary = [word for word, count in word_counts.items() if count >= 5]  # Limit vocabulary size\n",
    "        self.word_to_id = {word: i for i, word in enumerate(self.vocabulary)}\n",
    "        self.id_to_word = {i: word for i, word in enumerate(self.vocabulary)}\n",
    "        print(\"Vocabulary built.\")\n",
    "\n",
    "    def create_embedding_matrix(self):\n",
    "        print(\"Creating embedding matrix...\")\n",
    "        vocab_size = len(self.vocabulary)\n",
    "        self.embedding_matrix = np.zeros((vocab_size, self.embedding_dim))\n",
    "        for word, i in self.word_to_id.items():\n",
    "            if word in self.embeddings:\n",
    "                self.embedding_matrix[i] = self.embeddings[word]\n",
    "        print(\"Embedding matrix created.\")\n",
    "\n",
    "    def save_model(self, save_path):\n",
    "        \"\"\"Save the embedding matrix and vocabulary.\"\"\"\n",
    "        print(\"Saving the model...\")\n",
    "        np.save(save_path + '_embeddings.npy', self.embedding_matrix)\n",
    "        with open(save_path + '_vocab.txt', 'w') as f:\n",
    "            for word in self.vocabulary:\n",
    "                f.write(word + '\\n')\n",
    "        print(\"Model saved.\")\n",
    "\n",
    "    def load_model(self, load_path):\n",
    "        \"\"\"Load the embedding matrix and vocabulary.\"\"\"\n",
    "        print(\"Loading the model...\")\n",
    "        self.embedding_matrix = np.load(load_path + '_embeddings.npy')\n",
    "        with open(load_path + '_vocab.txt', 'r') as f:\n",
    "            self.vocabulary = [line.strip() for line in f]\n",
    "        self.word_to_id = {word: i for i, word in enumerate(self.vocabulary)}\n",
    "        self.id_to_word = {i: word for i, word in enumerate(self.vocabulary)}\n",
    "        print(\"Model loaded.\")\n",
    "\n",
    "# Example usage\n",
    "glove_loader = GloveEmbeddingLoader('glove.twitter.27B/glove.twitter.27B.200d.txt', 'IMDB Dataset.csv')\n",
    "glove_loader.load_glove_embeddings()\n",
    "glove_loader.preprocess_data()\n",
    "glove_loader.build_vocabulary(glove_loader.corpus)\n",
    "glove_loader.create_embedding_matrix()\n",
    "glove_loader.save_model('glove_model')\n",
    "glove_loader.load_model('glove_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
